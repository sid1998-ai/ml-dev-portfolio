{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03fa2e79-20ed-468e-8611-ec6684fc9981",
   "metadata": {},
   "source": [
    "Part 1: Load Cleaned Data + Split for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "197690dd-602f-48dd-ad14-b1139cb9274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"titanic_cleaned.csv\")\n",
    "\n",
    "#Question:: How many different files can we read?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d484a-aff0-4d88-aced-7f4cdd9e6768",
   "metadata": {},
   "source": [
    "📂 Structured Data Files\n",
    "Format\tFunction\tExample Use\n",
    "CSV\tpd.read_csv()\tMost common flat file for datasets\n",
    "Excel (XLSX)\tpd.read_excel()\tReports, tables from businesses\n",
    "JSON\tpd.read_json()\tAPIs or nested data (web scraping)\n",
    "HTML\tpd.read_html()\tTables from websites\n",
    "SQL\tpd.read_sql()\tPull data directly from databases\n",
    "Parquet\tpd.read_parquet()\tBig data, fast columnar storage\n",
    "Pickle\tpd.read_pickle()\tPython-native serialized objects\n",
    "ORC\tpd.read_orc()\tBig data, like Parquet (less common)\n",
    "Feather\tpd.read_feather()\tFast I/O, good for ML pipelines\n",
    "Clipboard\tpd.read_clipboard()\tQuick copy-paste of tabular data\n",
    "Text\tpd.read_table()\tText files with delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce60af96-2b6a-4a6c-baed-33ddad30759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df = df.drop('Embarked_C',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6e2c463-6c98-44e1-b725-e4488298d330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 9)\n",
      "(889,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Define features and target\n",
    "X= df.drop('Survived',axis = 1)\n",
    "y = df['Survived']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#Question: do we always define features and target before creating a model? 2) do we always drop this target variable from X 3)is there any thumb\n",
    "#rule for defining features and targets 4) why do we use axis = 1 4)explain more about sklearn.model_selection and train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0b87a-aff2-4d81-825b-122bd4770d67",
   "metadata": {},
   "source": [
    " Q1: Do we always define features and target before creating a model?\n",
    "✅ YES — Always.\n",
    "Every supervised ML model needs:\n",
    "\n",
    "X (features) → What the model uses to make predictions\n",
    "\n",
    "y (target/label) → What the model is trying to predict\n",
    "\n",
    "This is the core of supervised learning.\n",
    "\n",
    "✅ Q2: Do we always drop the target from X?\n",
    "✅ YES — Always.\n",
    "If you keep y (target column like Survived) in your features:\n",
    "\n",
    "The model “cheats” — it's like giving it the answer during training\n",
    "\n",
    "You'll get super high accuracy — but it's completely fake\n",
    "\n",
    "So this line is a must:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "X = df.drop('Survived', axis=1)\n",
    "✅ Q3: Is there a thumb rule for defining features and targets?\n",
    "✅ YES — Here's the logic:\n",
    "Type\tMeaning\tExample\n",
    "Target (y)\tThe column you want to predict\tSurvived, Price, Churn, IsSpam\n",
    "Features (X)\tThe data used to make predictions\tEverything except the target\n",
    "\n",
    "👉 You exclude columns like:\n",
    "\n",
    "IDs\n",
    "\n",
    "Target label\n",
    "\n",
    "Columns you wouldn't know in real time (like future info)\n",
    "\n",
    "✅ Q4: Why axis=1?\n",
    "In pandas:\n",
    "\n",
    "Axis\tMeaning\n",
    "axis=0\tOperate row-wise\n",
    "axis=1\tOperate column-wise ✅\n",
    "\n",
    "So:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "df.drop('Survived', axis=1)\n",
    "Means: drop the 'Survived' column, not a row.\n",
    "\n",
    "✅ Q5: What is train_test_split and sklearn.model_selection?\n",
    "📦 sklearn.model_selection\n",
    "This is the module in Scikit-learn where all the model selection tools live:\n",
    "\n",
    "train_test_split\n",
    "cross_val_score\n",
    "GridSearchCV\n",
    "StratifiedKFold\n",
    "RandomizedSearchCV\n",
    "\n",
    "📌 train_test_split does exactly what it says:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "Parameter\tMeaning\n",
    "X, y\tYour features and target\n",
    "test_size=0.2\t20% of the data goes into test set\n",
    "random_state=42\tEnsures same split every time (for reproducibility)\n",
    "\n",
    "🎯 Why We Do This:\n",
    "To train on one part of the data (X_train, y_train)\n",
    "\n",
    "And test generalization on unseen data (X_test, y_test)\n",
    "\n",
    "This simulates real-world usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "012a8d9b-6e24-40a3-b762-b5dbaaf712e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X , y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Questions: 1) what are we achieving here? 2)Why X capital y small 3)Explain parameters for train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8041569f-6925-4bc5-bfc2-1acec296155b",
   "metadata": {},
   "source": [
    "✅ Q1: What are we achieving with train_test_split?\n",
    "🎯 Purpose:\n",
    "We are splitting the dataset into two parts:\n",
    "\n",
    "Training set: Used to train the model (X_train, y_train)\n",
    "\n",
    "Testing set: Used to evaluate how well the model performs on unseen data (X_test, y_test)\n",
    "\n",
    "💡 Why it’s important:\n",
    "If you train and test on the same data, the model may memorize instead of learning → leads to overfitting.\n",
    "\n",
    "✅ train_test_split simulates the real world, where you don’t get to see test data during training.\n",
    "\n",
    "✅ Q2: Why is X capital and y small?\n",
    "It’s just a convention, but here’s the meaning:\n",
    "\n",
    "Symbol\tMeaning\n",
    "X (uppercase)\tA matrix of features — many rows and columns\n",
    "y (lowercase)\tA vector (single column) — your target label\n",
    "\n",
    "✅ This matches linear algebra conventions from math/ML.\n",
    "\n",
    "Example:\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "X.shape → (800, 6)   # 800 samples, 6 features  \n",
    "y.shape → (800,)     # 800 target values\n",
    "✅ Q3: Explain train_test_split() Parameters\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "Parameter\tPurpose\n",
    "X, y\tFeatures and target\n",
    "test_size=0.2\t20% of the data goes to testing, 80% to training\n",
    "train_size=0.8\t(Optional) — works with test_size\n",
    "random_state=42\tSets the random seed → ensures the same split every time (for reproducibility)\n",
    "shuffle=True (default)\tRandomly shuffles data before splitting\n",
    "\n",
    "🎯 Why random_state=42?\n",
    "If you don’t set this, every run splits differently → hard to debug or compare.\n",
    "\n",
    "By setting a number (any number, 42 is a meme 😄), you get consistent, repeatable splits.\n",
    "\n",
    "🧠 TL;DR Summary:\n",
    "train_test_split helps prevent overfitting by giving your model a realistic test\n",
    "\n",
    "X = matrix of features, y = vector of targets\n",
    "\n",
    "test_size=0.2 = hold out 20% for testing\n",
    "\n",
    "random_state=42 = ensure consistent split\n",
    "\n",
    "✅ Always split before training any model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e60bf9e-c728-44df-afb0-cf70d369a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets train a Logistic Regression model that predicts survival — and this is where machine learning actually happens\n",
    "#Part 2 – Train & Evaluate Logistic Regression\n",
    "#Step 1: Import Required Tools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "#Question:1)Why are we using Logisctic Regression model? 2)what is thumb rule to decide a model 3)What are metrics how are they useful and when to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92ab68fc-bf18-4329-83df-c40807768d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# max_iter=1000 ensures the model has enough time to converge. Default is often too low.\n",
    "\n",
    "#Questions:1)What happens when we call the fit function? 2)is max_iter 1000 in milliseconds? how does it impact?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79a9d43-af61-42fb-8d00-a85228337d99",
   "metadata": {},
   "source": [
    " Q1: What happens when we call .fit()?\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "🎯 .fit() = Train the model\n",
    "The model looks at each row in X_train, compares its prediction to the real y_train, and adjusts itself to minimize error.\n",
    "\n",
    "⚙️ For Logistic Regression, .fit() means:\n",
    "The model initializes some random weights (coefficients)\n",
    "\n",
    "For each row, it calculates a predicted probability\n",
    "\n",
    "It compares that to the true label (0 or 1)\n",
    "\n",
    "Then it adjusts the weights using a method like Gradient Descent to reduce the overall prediction error (called loss)\n",
    "\n",
    "This cycle repeats until the model converges — meaning the changes are very small and it's \"happy\" with the result\n",
    "\n",
    "✅ You dont need to manually do any math — but thats the core of whats happening!\n",
    "\n",
    "✅ Q2: Is max_iter=1000 in milliseconds?\n",
    "❌ No — it's not time, it’s number of training cycles, called iterations.\n",
    "\n",
    "💡 What max_iter=1000 really means:\n",
    "\"Try up to 1000 rounds of adjusting weights during training.\"\n",
    "\n",
    "If the model converges (stabilizes) earlier, it stops.\n",
    "If not, it continues up to 1000 iterations.\n",
    "\n",
    "⚠️ Why we increase it:\n",
    "The default max_iter is often 100 or 200, which may not be enough for the model to fully converge, especially:\n",
    "\n",
    "With many features\n",
    "\n",
    "When the data is scaled weirdly\n",
    "\n",
    "Or when the model needs more time to find the optimal weights\n",
    "\n",
    "✅ By setting max_iter=1000, you're making sure the model has enough chance to learn.\n",
    "\n",
    "❗ If you don’t increase it and it doesn’t converge:\n",
    "You’ll see this warning:\n",
    "\n",
    "vbnet\n",
    "Copy\n",
    "Edit\n",
    "ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
    "✅ TL;DR:\n",
    "Concept\tMeaning\n",
    ".fit()\tTrains the model by learning from X and y\n",
    "max_iter=1000\tUp to 1000 rounds of training (not time-based)\n",
    "Why 1000?\tHelps prevent convergence failure, especially with larger datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec4e8e8f-bbb3-46cc-98d2-31ce481d6baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1\n",
      " 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1\n",
      " 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Predict on Test Data\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9a350a0-81dd-4b53-82c8-f0da3b8fc1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7808988764044944\n",
      "Confusion Matrix:\n",
      " [[86 23]\n",
      " [16 53]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82       109\n",
      "           1       0.70      0.77      0.73        69\n",
      "\n",
      "    accuracy                           0.78       178\n",
      "   macro avg       0.77      0.78      0.77       178\n",
      "weighted avg       0.79      0.78      0.78       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred_lr))\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred_lr))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582c026-00af-4ef5-8c33-fa12c6a3d700",
   "metadata": {},
   "source": [
    "| Metric                  | What It Tells You                |\n",
    "| ----------------------- | -------------------------------- |\n",
    "| **Accuracy**            | Overall % of correct predictions |\n",
    "| **Confusion Matrix**    | How many TP, TN, FP, FN          |\n",
    "| **Precision/Recall/F1** | How good model is for each class |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820b03f2-cca9-4458-a4a1-4462b44ea90e",
   "metadata": {},
   "source": [
    "✅ Q1: Why are we using Logistic Regression here?\n",
    "Because your target variable Survived is:\n",
    "\n",
    "Binary → Only two values: 0 (did not survive), 1 (survived)\n",
    "\n",
    "🔍 Logistic Regression is the go-to model when:\n",
    "Case\tReason\n",
    "🎯 Target is binary (0/1, yes/no, true/false)\t✅ Logistic regression is designed for this\n",
    "🔢 You want to predict probabilities\t✅ It outputs a probability (e.g., “80% chance survived”)\n",
    "💬 You need a simple, interpretable model\t✅ Easy to explain to non-technical people\n",
    "🧠 You want a baseline model\t✅ Great starting point before trying complex models\n",
    "\n",
    "✅ Q2: What’s the thumb rule to decide which model to use?\n",
    "There’s no one-size-fits-all, but here’s a cheat sheet:\n",
    "\n",
    "Problem Type\tUse These Models (start with first)\n",
    "✅ Binary Classification (0/1)\tLogistic Regression, Decision Tree, Random Forest\n",
    "🎯 Multiclass Classification\tDecision Tree, Random Forest, Gradient Boosting, XGBoost\n",
    "🧮 Regression (predicting numbers)\tLinear Regression, Decision TreeRegressor, Random Forest\n",
    "🧠 Text/NLP\tNaive Bayes, Logistic Regression, Transformers\n",
    "🖼️ Images\tCNNs (via deep learning)\n",
    "💥 Large data / nonlinear\tRandom Forest, Gradient Boost, XGBoost, SVM\n",
    "\n",
    "✅ Rule: Always start simple (LogReg or Tree), then move to complex if needed.\n",
    "\n",
    "✅ Q3: What are metrics in ML? Why and when to use?\n",
    "🧠 Definition:\n",
    "Metrics are scores that tell you how good or bad your model is performing.\n",
    "\n",
    "📏 Why do we use them?\n",
    "Because just accuracy is often not enough — we need to know:\n",
    "\n",
    "What kinds of errors the model is making\n",
    "\n",
    "Is it biased toward a class?\n",
    "\n",
    "Is it good at catching rare events (like fraud detection)?\n",
    "\n",
    "✅ Common Classification Metrics:\n",
    "Metric\tWhat It Tells You\tWhen to Use\n",
    "Accuracy\t% of total correct predictions\t✅ Only when data is balanced\n",
    "Precision\tOf all predicted positives, how many were correct?\t✅ When false positives are costly (e.g., spam detection)\n",
    "Recall\tOf all actual positives, how many did we find?\t✅ When false negatives are costly (e.g., cancer detection)\n",
    "F1 Score\tBalance between precision & recall\t✅ When you want a single score for imbalanced data\n",
    "Confusion Matrix\tBreakdown of TP, TN, FP, FN\t✅ For analyzing detailed performance\n",
    "\n",
    "🧪 Example:\n",
    "You’re predicting spam email (0 = not spam, 1 = spam)\n",
    "\n",
    "You care about not marking real emails as spam → Precision is more important\n",
    "\n",
    "You care about not missing any spam at all → Recall is more important\n",
    "\n",
    "⚠️ Why Not Just Use Accuracy?\n",
    "Example\tAccuracy Looks Good, But...\n",
    "Fraud detection (99.9% not fraud)\tA model that always predicts “no fraud” = 99.9% accuracy, but totally useless\n",
    "Rare disease detection\tModel misses most sick patients, still gets “good” accuracy\n",
    "\n",
    "✅ TL;DR Summary:\n",
    "Concept\tKey Point\n",
    "Logistic Regression\tBest for binary target\n",
    "Model choice\tStart simple, depends on task\n",
    "Metrics\tEvaluate how and where your model is right or wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe94538-c61e-4a1f-a986-888e2f5cb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now compare this model with other models\n",
    "#We now test if Decision Tree or Random Forest can beat Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a66c4cc-0d59-4e0f-a875-2c5f2e377d01",
   "metadata": {},
   "source": [
    "| Model             | What It Brings                     |\n",
    "| ----------------- | ---------------------------------- |\n",
    "| **Decision Tree** | Handles non-linear patterns better |\n",
    "| **Random Forest** | More accurate, less overfitting    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0763c65b-964a-4a49-9504-ef4a9c708a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy: 0.7303370786516854\n",
      "DT ConfusionMatrix: [[79 30]\n",
      " [18 51]]\n",
      "DT ClassificationReport:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.77       109\n",
      "           1       0.63      0.74      0.68        69\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.72      0.73      0.72       178\n",
      "weighted avg       0.74      0.73      0.73       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"DT Accuracy:\",accuracy_score(y_test,y_pred_dt))\n",
    "print(\"DT ConfusionMatrix:\",confusion_matrix(y_test,y_pred_dt))\n",
    "print(\"DT ClassificationReport:\",classification_report(y_test,y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b586b57-f275-49d5-a5be-6cfd278a84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 0.797752808988764\n",
      "RF ConfusionMatrix:\n",
      " [[92 17]\n",
      " [19 50]]\n",
      "RF ClassificationReport:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       109\n",
      "           1       0.75      0.72      0.74        69\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.79      0.78      0.79       178\n",
      "weighted avg       0.80      0.80      0.80       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf= RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"RF Accuracy:\",accuracy_score(y_test,y_pred_rf))\n",
    "print(\"RF ConfusionMatrix:\\n\",confusion_matrix(y_test,y_pred_rf))\n",
    "print(\"RF ClassificationReport:\\n\",classification_report(y_test,y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07304080-e075-4b1f-83e8-8340febb9c74",
   "metadata": {},
   "source": [
    "Step 1: Confusion Matrix — What Is It?\n",
    "Let’s say you're predicting if a passenger survived (1) or did not survive (0):\n",
    "Here’s a possible confusion matrix output:\n",
    "\n",
    "lua\n",
    "Copy\n",
    "Edit\n",
    "               Predicted\n",
    "             |  0  |  1  \n",
    "         -----------------\n",
    "   Actual 0 | TN  | FP  \n",
    "   Actual 1 | FN  | TP  \n",
    "Term\tMeaning\n",
    "TP (True Positive)\tModel predicted 1 (survived), and it's correct ✅\n",
    "TN (True Negative)\tModel predicted 0 (did not survive), and it's correct ✅\n",
    "FP (False Positive)\tModel predicted 1, but it was actually 0 ❌\n",
    "FN (False Negative)\tModel predicted 0, but it was actually 1 ❌\n",
    "\n",
    "💡 Example:\n",
    "You predicted survival:\n",
    "\n",
    "Passenger\tTrue\tPredicted\tType\n",
    "1\t1\t1\t✅ TP\n",
    "2\t0\t1\t❌ FP\n",
    "3\t0\t0\t✅ TN\n",
    "4\t1\t0\t❌ FN\n",
    "\n",
    "📊 Step 2: Classification Report Breakdown\n",
    "This gives you:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "print(classification_report(y_test, y_pred))\n",
    "Output:\n",
    "\n",
    "Metric\tClass 0\tClass 1\n",
    "Precision\t0.75\t0.68\n",
    "Recall\t0.79\t0.63\n",
    "F1-score\t0.77\t0.65\n",
    "Support\t110\t79\n",
    "\n",
    "Let’s decode them:\n",
    "\n",
    "✅ Precision:\n",
    "Of all passengers the model predicted as survived (1), how many actually survived?\n",
    "\n",
    "ini\n",
    "Copy\n",
    "Edit\n",
    "Precision = TP / (TP + FP)\n",
    "✅ High precision = few false alarms\n",
    "👉 Useful when false positives are expensive (e.g., spam filter)\n",
    "\n",
    "✅ Recall:\n",
    "Of all passengers who actually survived, how many did the model correctly catch?\n",
    "\n",
    "ini\n",
    "Copy\n",
    "Edit\n",
    "Recall = TP / (TP + FN)\n",
    "✅ High recall = few missed actual cases\n",
    "👉 Useful when false negatives are dangerous (e.g., cancer detection)\n",
    "\n",
    "✅ F1 Score:\n",
    "Balance between precision & recall (good when data is imbalanced)\n",
    "\n",
    "ini\n",
    "Copy\n",
    "Edit\n",
    "F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "✅ Think of it as the overall skill of the model at that class.\n",
    "\n",
    "✅ Support:\n",
    "Number of actual occurrences in your test set\n",
    "(so if 79 people actually survived, support for class 1 = 79)\n",
    "\n",
    "🧠 TL;DR Summary\n",
    "Term\tThink of It As...\tFormula\n",
    "Precision\t\"How accurate are my positive predictions?\"\tTP / (TP + FP)\n",
    "Recall\t\"How well did I catch all real positives?\"\tTP / (TP + FN)\n",
    "F1 Score\t\"Balanced score of precision & recall\"\tharmonic mean\n",
    "Accuracy\t\"Overall correctness\"\t(TP + TN) / Total\n",
    "\n",
    "✅ Easy Analogy:\n",
    "Imagine a COVID test:\n",
    "\n",
    "Term\tMeaning\n",
    "TP\tSick person → test says \"positive\" ✅\n",
    "FP\tHealthy person → test says \"positive\" ❌\n",
    "FN\tSick person → test says \"negative\" ❌ (dangerous)\n",
    "TN\tHealthy person → test says \"negative\" ✅\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cda19e-f7bf-42f2-97ea-afa707a57354",
   "metadata": {},
   "source": [
    "Precision vs recall\n",
    "\n",
    "\n",
    "Both precision and recall focus on the positive class (usually 1 = something happened, like survived, or fraud, or spam).\n",
    "\n",
    "🧠 Think of Precision and Recall Like This:\n",
    "Metric\tFocuses on...\tReal-Life Analogy\n",
    "Precision ✅\t\"Of what I predicted as positive, how many were actually correct?\"\t📥 Email: Of all emails marked spam, how many actually were spam?\n",
    "Recall 🔍\t\"Of all actual positives, how many did I catch?\"\t🧪 COVID Test: Of all people who had COVID, how many did the test correctly catch?\n",
    "\n",
    "⚖️ Precision vs Recall = Quality vs Coverage\n",
    "Precision\tRecall\n",
    "✅ High Precision\tLess false positives (fewer wrong positives)\tYou’re confident in positives\n",
    "✅ High Recall\tLess false negatives (fewer misses)\tYou catch more real cases\n",
    "❌ Low Precision\tModel guesses “positive” too often, many wrong\t\n",
    "❌ Low Recall\tModel misses real positives (dangerous)\t\n",
    "\n",
    "🔥 Easy Trick to Remember:\n",
    "Precision = How precise is the model when it says \"Yes\"?\n",
    "Recall = Did the model remember to catch all the real Yes cases?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd2f65-7e80-4a94-9d74-7323cbbcef0a",
   "metadata": {},
   "source": [
    "🧪 Example:\n",
    "There are 10 real celebrities\n",
    "You let in 6 people\n",
    "But only 3 were real celebrities\n",
    "\n",
    "Precision = 3 out of 6 → 3/6 = 0.5\n",
    "\n",
    "Recall = 3 out of 10 → 3/10 = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca07b23e-3e23-433f-aecc-265103d8e176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
